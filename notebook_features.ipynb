{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asvpKRf8VjTH"
      },
      "source": [
        "## Projeto 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imutils in d:\\users\\heinr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.5.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
            "You should consider upgrading via the 'd:\\Users\\heinr\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade imutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gBiILMIpVjTS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50, InceptionV3, InceptionResNetV2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, classification_report\n",
        "from sklearn.preprocessing import Normalizer, MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer, LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocessamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def crop_brain_contour(image, plot=False):\n",
        "    \n",
        "    import imutils\n",
        "    import cv2\n",
        "    from matplotlib import pyplot as plt\n",
        "    \n",
        "    # Convert the image to grayscale, and blur it slightly\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "     #Threshold the image, then perform a series of erosions +\n",
        "     #dilations to remove any small regions of noise\n",
        "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "    thresh = cv2.erode(thresh, None, iterations=2)\n",
        "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
        "\n",
        "    #Find contours in thresholded image, then grab the largest one\n",
        "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "    c = max(cnts, key=cv2.contourArea)\n",
        "    \n",
        "\n",
        "    # Find the extreme points\n",
        "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n",
        "    \n",
        "    return new_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def corta_img(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0.7)\n",
        "    #plt.imshow(gray)\n",
        "\n",
        "    (T, thresh) = cv2.threshold(gray, 155, 255, cv2.THRESH_BINARY)\n",
        "    plt.imshow(thresh)\n",
        "    # (T, threshInv) = cv2.threshold(gray, 155, 255, cv2.THRESH_BINARY_INV)\n",
        "    # plt.imshow(threshInv)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 5))\n",
        "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "    closed = cv2.erode(closed, None, iterations = 19)\n",
        "    closed = cv2.dilate(closed, None, iterations = 17)\n",
        "    #plt.imshow(closed)\n",
        "    ret,mask = cv2.threshold(closed, 155, 255, cv2.THRESH_BINARY) \n",
        "    #apply AND operation on image and mask generated by thrresholding\n",
        "    final = cv2.bitwise_and(image,image,mask = mask) \n",
        "\n",
        "    return final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def equalizeHist(img):\n",
        "    b,g,r = cv2.split(img)\n",
        "    \n",
        "    #apply hist equ on the three channels separately\n",
        "    b = cv2.equalizeHist(b)\n",
        "    g = cv2.equalizeHist(g)\n",
        "    r = cv2.equalizeHist(r)\n",
        "    \n",
        "    #merge all the three channels\n",
        "    equ = cv2.merge((b,g,r))\n",
        "    \n",
        "    #convert it to RGB to visualize\n",
        "    new_img = cv2.cvtColor(equ,cv2.COLOR_BGR2RGB);\n",
        "    return new_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clahe(img):\n",
        "    #do the same as we did for histogram equalization\n",
        "    #set the clip value and the gridsize changing these values will give different output\n",
        "    clahe = cv2.createCLAHE(clipLimit=6, \\\n",
        "                        tileGridSize=(16,16))\n",
        "    \n",
        "    #split the three channels\n",
        "    b,g,r = cv2.split(img)\n",
        "    \n",
        "    #apply CLAHE on the three channels separately\n",
        "    b = clahe.apply(b)\n",
        "    g = clahe.apply(g)\n",
        "    r = clahe.apply(r)\n",
        "    \n",
        "    #merge the three channels\n",
        "    bgr = cv2.merge((b,g,r))\n",
        "    \n",
        "    #convert to RGB and plot\n",
        "    newimage = cv2.cvtColor(bgr,cv2.COLOR_BGR2RGB);\n",
        "    return newimage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detecta_anorm(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY, 0.7)\n",
        "    #plt.imshow(gray)\n",
        "\n",
        "    (T, thresh) = cv2.threshold(gray, 155, 255, cv2.THRESH_BINARY)\n",
        "    #plt.imshow(thresh)\n",
        "    # (T, threshInv) = cv2.threshold(gray, 155, 255, cv2.THRESH_BINARY_INV)\n",
        "    # plt.imshow(threshInv)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 5))\n",
        "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
        "    closed = cv2.erode(closed, None, iterations = 19)\n",
        "    closed = cv2.dilate(closed, None, iterations = 17)\n",
        "    #plt.imshow(closed)\n",
        "\n",
        "    def auto_canny(image, sigma=0.33):\n",
        "        # compute the median of the single channel pixel intensities\n",
        "        v = np.median(image)\n",
        "        # apply automatic Canny edge detection using the computed median\n",
        "        lower = int(max(0, (1.0 - sigma) * v))\n",
        "        upper = int(min(255, (1.0 + sigma) * v))\n",
        "        edged = cv2.Canny(image, lower, upper)\n",
        "        # return the edged image\n",
        "        return edged\n",
        "    canny = auto_canny(closed)\n",
        "\n",
        "    (cnts, _) = cv2.findContours(canny.copy(), cv2.RETR_EXTERNAL,\n",
        "    cv2.CHAIN_APPROX_SIMPLE)\n",
        "    new_img = cv2.drawContours(image, cnts, -1, (0, 0, 255), 2)\n",
        "    return new_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### -------------------------- COMEÃ‡A AQUI ------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ort_dLIVWNg0"
      },
      "source": [
        "## Features Treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "C-XPYYSs6ppM"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Carrega as imagens de treinamento e salva os labels\n",
        "#\n",
        "\n",
        "train_path = ('train/')      \n",
        "dirs = os.listdir( train_path )\n",
        "img_size= 224\n",
        "\n",
        "train_img = []\n",
        "indices = []\n",
        "\n",
        "for file in dirs:\n",
        "   numbers = re.sub('[^0-9]', '', file)\n",
        "   indices.append(numbers)\n",
        "\n",
        "indices = (np.array(indices))\n",
        "indices = sorted(indices, key=int)\n",
        "\n",
        "for i in range(len(indices)):\n",
        "   img_ori = cv2.imread(train_path + str(indices[i])+'.jpg')\n",
        "   img_crop = crop_brain_contour(img_ori, True)\n",
        "   #img_clahe = clahe(img_crop)\n",
        "   img_equalize = equalizeHist(img_crop)\n",
        "   #img_anorm = detecta_anorm(img_equalize)\n",
        "   #img_anorm = corta_img(img_equalize) \n",
        "   \n",
        "   train_img.append(cv2.resize(img_equalize, (img_size,img_size)))  \n",
        "\n",
        "train_img = (np.array(train_img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_vr_4qjbVjTZ"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Carrega o modelo ResNet50\n",
        "#\n",
        "\n",
        "base_model = ResNet50(weights='imagenet')\n",
        "model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGzZx5TYVjTa",
        "outputId": "eb47c763-2ce5-49c8-bed9-10471e6db771"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# extrator de features train\n",
        "#\n",
        "\n",
        "train_features_array = np.zeros((train_img.shape[0],2048))\n",
        "\n",
        "for i, img_pos in enumerate(train_img):\n",
        "  try:\n",
        "    img = img_pos\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    features = model.predict(x)\n",
        "    features = features.reshape(2048,)\n",
        "    train_features_array[i,:] = features\n",
        "  except:\n",
        "    print(img_pos)\n",
        "\n",
        "print(train_features_array.shape)\n",
        "\n",
        "compress = pd.DataFrame(train_features_array)  \n",
        "compress.to_csv('./train_features_crop_equalize.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSisNApZWNg7"
      },
      "source": [
        "## Features Testes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaxFKdljWNg8"
      },
      "outputs": [],
      "source": [
        "test_path = ('./test/')\n",
        "dirs = os.listdir( test_path )\n",
        "dirs.sort()\n",
        "img_size= 224\n",
        "\n",
        "test_img = []\n",
        "test_label = []\n",
        "\n",
        "for file in dirs:\n",
        "    if \".jpg\" in file:\n",
        "        img_ori = cv2.imread(test_path + str(file))\n",
        "        img_crop = crop_brain_contour(img_ori, True)\n",
        "        #img_clahe = clahe(img_crop)\n",
        "        img_equalize = equalizeHist(img_crop)\n",
        "        #img_anorm = detecta_anorm(img_equalize) \n",
        "        #img_anorm = corta_img(img_equalize) \n",
        "        test_img.append(cv2.resize(img_equalize, (img_size,img_size)))\n",
        "        test_label.append(file.split('.')[0])\n",
        "\n",
        "test_img = (np.array(test_img))\n",
        "print(test_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5Aee-aXVjTb"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Gerador de features test\n",
        "#\n",
        "\n",
        "teste_features_array = np.zeros((test_img.shape[0],2048))\n",
        "\n",
        "for i, img_pos in enumerate(test_img):\n",
        "  try:\n",
        "    img = img_pos\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    features = model.predict(x)\n",
        "    features = features.reshape(2048,)\n",
        "    teste_features_array[i,:] = features\n",
        "  except:\n",
        "    print(img_pos)\n",
        "\n",
        "compress = pd.DataFrame(teste_features_array)  \n",
        "compress.to_csv('./test_features_crop_equalize.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "5c81342a127fbeec5adc3670d734e9b749530cf9eb127c557da42f37ad987919"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
